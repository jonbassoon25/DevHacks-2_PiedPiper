# DevHacks-2_PiedPiper — Quick Start

This repository produces per-row location/activity tags with a local Ollama model (gemma2), converts tags to fixed-size vectors, and runs the application that consumes those vectors.

Summary run order (canonical)
1. Start Ollama (gemma2) and keep it running.
2. Generate per-row tags: Python_ML/build_tags.py → produces `location_tags.json` and `location_tags.npy`.
3. Vectorize tags: Python_ML/vectorize_tags.py → produces `location_vectors.npy`.
4. Start the app: `node app.js` (project root) — app reads the vectors.

Prerequisites
- Python 3.10+
- Node.js (for app.js)
- Ollama installed with model `gemma2` available
- From project root, install Python deps if you need them:
  - PowerShell:
    cd c:\Users\nneithal\Documents\GitHub\DevHacks-2_PiedPiper\Python_ML
    .\Scripts\Activate.ps1   # if using the included venv
    pip install -r requirements.txt

Start Ollama (required for high-quality tags)
- In a terminal:
  ollama run gemma2
- If Ollama will run on a different host/port, set the environment variable before running scripts:
  - PowerShell (session):
    $env:OLLAMA_URL = 'http://127.0.0.1:11434'
    $env:OLLAMA_MODEL = 'gemma2'
- Verify API:
  Invoke-RestMethod -Uri 'http://localhost:11434/api/models' -Method Get -TimeoutSec 5

Step 1 — Generate tags (build_tags.py)
- Go to Python_ML and run:
  python build_tags.py
- Behavior:
  - By default the script requires Ollama and will raise an error if Ollama is unreachable.
  - To explicitly allow the heuristic fallback (not recommended for production), run:
    python build_tags.py --allow-heuristic
- Outputs (Python_ML folder):
  - location_tags.npy — NumPy object-array (one element per row; each element is a list of tags). Load with np.load(..., allow_pickle=True).
  - location_tags.json — JSON list-of-lists (same data, human readable)

Step 2 — Vectorize tags (vectorize_tags.py)
- After tags are produced:
  python vectorize_tags.py
- Expected output:
  - location_vectors.npy — fixed-size numeric vectors for each row (shape: n_rows × n_features)
- Notes:
  - vectorize_tags.py builds a common tag vocabulary so all vectors have the same length.
  - Configure min-frequency, seeding, or normalization in vectorize_tags.py to stabilize vocabulary across dataset changes.

Step 3 — Run the application (app.js)
- From project root:
  npm install   # if needed
  node app.js
- The app should load `location_vectors.npy` or the configured filename.

Inspect outputs
- Load tags array:
  import numpy as np
  tags = np.load("Python_ML/location_tags.npy", allow_pickle=True)
  print(len(tags), tags[0])
- View JSON:
  import json
  with open("Python_ML/location_tags.json","r",encoding="utf-8") as f:
      data = json.load(f)

Troubleshooting
- RuntimeError: Ollama not reachable at http://localhost:11434
  - Ensure Ollama is running (ollama run gemma2) and the API `/api/models` is reachable.
  - If Ollama is running in WSL/Docker/VM, use the correct host or set OLLAMA_URL.
  - If the model is still downloading/warming, wait until Ollama prints readiness logs.
- If you prefer to test without Ollama, use:
  python build_tags.py --allow-heuristic
  (Heuristic tagging is explicit opt-in only.)
- If tags vocabulary is too noisy:
  - Increase min-count threshold in vectorize_tags.py
  - Provide a seed vocabulary to vectorize_tags.py
  - Merge/normalize synonyms or apply stemming/lemmatization

Files of interest
- Python_ML/build_tags.py  — generate per-row tags (Ollama-first)
- Python_ML/vectorize_tags.py — build fixed-size vectors from tags
- Python_ML/location_tags.json / location_tags.npy — tag outputs
- Python_ML/location_vectors.npy — vector outputs (generated by vectorize_tags.py)
- app.js — application that consumes vectors
- build_embeddings.py — legacy embedding pipeline (keep until you confirm build_tags+vectorize flow)

Recommendations
- Keep Ollama running while generating tags (do not restart between rows).
- For reproducible vectors across dataset changes, maintain a seed vocabulary or increase min frequency.
- Add caching for prompt→tags if dataset contains many duplicate descriptions.

If you want, I can:
- Add a small PowerShell wrapper that starts Ollama, waits for readiness, and runs the two Python steps.
- Add CLI flags to vectorize_tags.py to control vocabulary thresholds and output names.
````// filepath: c:\Users\nneithal\Documents\GitHub\DevHacks-2_PiedPiper\README.md

# DevHacks-2_PiedPiper — Quick Start

This repository produces per-row location/activity tags with a local Ollama model (gemma2), converts tags to fixed-size vectors, and runs the application that consumes those vectors.

Summary run order (canonical)
1. Start Ollama (gemma2) and keep it running.
2. Generate per-row tags: Python_ML/build_tags.py → produces `location_tags.json` and `location_tags.npy`.
3. Vectorize tags: Python_ML/vectorize_tags.py → produces `location_vectors.npy`.
4. Start the app: `node app.js` (project root) — app reads the vectors.

Prerequisites
- Python 3.10+
- Node.js (for app.js)
- Ollama installed with model `gemma2` available
- From project root, install Python deps if you need them:
  - PowerShell:
    cd c:\Users\nneithal\Documents\GitHub\DevHacks-2_PiedPiper\Python_ML
    .\Scripts\Activate.ps1   # if using the included venv
    pip install -r requirements.txt

Start Ollama (required for high-quality tags)
- In a terminal:
  ollama run gemma2
- If Ollama will run on a different host/port, set the environment variable before running scripts:
  - PowerShell (session):
    $env:OLLAMA_URL = 'http://127.0.0.1:11434'
    $env:OLLAMA_MODEL = 'gemma2'
- Verify API:
  Invoke-RestMethod -Uri 'http://localhost:11434/api/models' -Method Get -TimeoutSec 5

Step 1 — Generate tags (build_tags.py)
- Go to Python_ML and run:
  python build_tags.py
- Behavior:
  - By default the script requires Ollama and will raise an error if Ollama is unreachable.
  - To explicitly allow the heuristic fallback (not recommended for production), run:
    python build_tags.py --allow-heuristic
- Outputs (Python_ML folder):
  - location_tags.npy — NumPy object-array (one element per row; each element is a list of tags). Load with np.load(..., allow_pickle=True).
  - location_tags.json — JSON list-of-lists (same data, human readable)

Step 2 — Vectorize tags (vectorize_tags.py)
- After tags are produced:
  python vectorize_tags.py
- Expected output:
  - location_vectors.npy — fixed-size numeric vectors for each row (shape: n_rows × n_features)
- Notes:
  - vectorize_tags.py builds a common tag vocabulary so all vectors have the same length.
  - Configure min-frequency, seeding, or normalization in vectorize_tags.py to stabilize vocabulary across dataset changes.

Step 3 — Run the application (app.js)
- From project root:
  npm install   # if needed
  node app.js
- The app should load `location_vectors.npy` or the configured filename.

Inspect outputs
- Load tags array:
  import numpy as np
  tags = np.load("Python_ML/location_tags.npy", allow_pickle=True)
  print(len(tags), tags[0])
- View JSON:
  import json
  with open("Python_ML/location_tags.json","r",encoding="utf-8") as f:
      data = json.load(f)

Troubleshooting
- RuntimeError: Ollama not reachable at http://localhost:11434
  - Ensure Ollama is running (ollama run gemma2) and the API `/api/models` is reachable.
  - If Ollama is running in WSL/Docker/VM, use the correct host or set OLLAMA_URL.
  - If the model is still downloading/warming, wait until Ollama prints readiness logs.
- If you prefer to test without Ollama, use:
  python build_tags.py --allow-heuristic
  (Heuristic tagging is explicit opt-in only.)
- If tags vocabulary is too noisy:
  - Increase min-count threshold in vectorize_tags.py
  - Provide a seed vocabulary to vectorize_tags.py
  - Merge/normalize synonyms or apply stemming/lemmatization

Files of interest
- Python_ML/build_tags.py  — generate per-row tags (Ollama-first)
- Python_ML/vectorize_tags.py — build fixed-size vectors from tags
- Python_ML/location_tags.json / location_tags.npy — tag outputs
- Python_ML/location_vectors.npy — vector outputs (generated by vectorize_tags.py)
- app.js — application that consumes vectors
- build_embeddings.py — legacy embedding pipeline (keep until you confirm build_tags+vectorize flow)

Recommendations
- Keep Ollama running while generating tags (do not restart between rows).
- For reproducible vectors across dataset changes, maintain a seed vocabulary or increase min frequency.
- Add caching for prompt→tags if dataset contains many duplicate descriptions.